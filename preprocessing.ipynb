{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e72e59fd4e3b4734a1839204a9d74cf8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73ff9a5f69fd4e53a5072cfefa6d7531","IPY_MODEL_35a650e5d4bb40df8bb9d0bf0799132b","IPY_MODEL_f8a24ac30dcc4303bfd2f08e2825fca2"],"layout":"IPY_MODEL_e559c28d63934ede822df8aff7634a9f"}},"73ff9a5f69fd4e53a5072cfefa6d7531":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f5967a9386347ccb185ee2116add86b","placeholder":"​","style":"IPY_MODEL_15010c60cf2d446d841189c3f94ba0b2","value":" 57%"}},"35a650e5d4bb40df8bb9d0bf0799132b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_424b74d22ff8440eb70fdec197ffc38e","max":63,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe272ecc743a4cd8b85beb28519ea242","value":36}},"f8a24ac30dcc4303bfd2f08e2825fca2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34cedcb7b9704974b09895d35d934092","placeholder":"​","style":"IPY_MODEL_507715d919bb40df9e93711565e07163","value":" 36/63 [00:17&lt;00:10,  2.69it/s]"}},"e559c28d63934ede822df8aff7634a9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f5967a9386347ccb185ee2116add86b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15010c60cf2d446d841189c3f94ba0b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"424b74d22ff8440eb70fdec197ffc38e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe272ecc743a4cd8b85beb28519ea242":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34cedcb7b9704974b09895d35d934092":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507715d919bb40df9e93711565e07163":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"nMI7CYxcyiUB"},"source":["Before running the file Upload all your data set on your goole drive in a zip format"]},{"cell_type":"code","metadata":{"id":"YjtnZQkTu6tX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722147671993,"user_tz":-330,"elapsed":28806,"user":{"displayName":"Mihir Patel","userId":"02200138481060467138"}},"outputId":"d77de4b0-7a3f-478c-afd3-3090415b40c5"},"source":["#Mount our google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"f4y_fGlmur4v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722147678801,"user_tz":-330,"elapsed":1359,"user":{"displayName":"Mihir Patel","userId":"02200138481060467138"}},"outputId":"77c435fc-0eac-46c5-838f-2ecafe82183c"},"source":["#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n","#download and unzip the data from google drive Colab environment\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","#use only file id of the link\n","#Note: Below link is just an example, Not an actual link. Actual Links are in ReadMe file\n","#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n","url = '1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\n","gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading 1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07 into ./data.zip... Done.\n","Unzipping..."]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/google_drive_downloader/google_drive_downloader.py:78: UserWarning: Ignoring `unzip` since \"1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07\" does not look like a valid zip file\n","  warnings.warn('Ignoring `unzip` since \"{}\" does not look like a valid zip file'.format(file_id))\n"]}]},{"cell_type":"code","metadata":{"id":"1f40EeRuvAkO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722147752095,"user_tz":-330,"elapsed":594,"user":{"displayName":"Mihir Patel","userId":"02200138481060467138"}},"outputId":"11c0d938-08ad-4bfe-f125-880ca523db9e"},"source":["#To get the average frame count\n","import json\n","import glob\n","import numpy as np\n","import cv2\n","import copy\n","#change the path accordingly\n","video_files =  glob.glob('/content/drive/MyDrive/data/*.mp4')\n","#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n","#video_files += video_files1\n","frame_count = []\n","for video_file in video_files:\n","  cap = cv2.VideoCapture(video_file)\n","  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<70):\n","    video_files.remove(video_file)\n","    continue\n","  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n","print(\"frames\" , frame_count)\n","print(\"Total number of videos: \" , len(frame_count))\n","print('Average frame per video:',np.mean(frame_count))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["frames [148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148]\n","Total number of videos:  63\n","Average frame per video: 148.0\n"]}]},{"cell_type":"code","metadata":{"id":"U92Ovn3JvV52","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722147841150,"user_tz":-330,"elapsed":28485,"user":{"displayName":"Mihir Patel","userId":"02200138481060467138"}},"outputId":"d3fef3d7-fb07-451d-c418-4bdff645fc89"},"source":["# to extract frame\n","def frame_extract(path):\n","  vidObj = cv2.VideoCapture(path)\n","  success = 1\n","  while success:\n","      success, image = vidObj.read()\n","      if success:\n","          yield image\n","!pip3 install face_recognition\n","# !mkdir '/content/drive/My Drive/Face_only_data'\n","import torch\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import face_recognition\n","from tqdm.autonotebook import tqdm\n","# process the frames\n","def create_face_videos(path_list,out_dir):\n","  already_present_count =  glob.glob(out_dir+'*.mp4')\n","  print(\"No of videos already present \" , len(already_present_count))\n","  for path in tqdm(path_list):\n","    out_path = os.path.join(out_dir,path.split('/')[-1])\n","    file_exists = glob.glob(out_path)\n","    if(len(file_exists) != 0):\n","      print(\"File Already exists: \" , out_path)\n","      continue\n","    frames = []\n","    flag = 0\n","    face_all = []\n","    frames1 = []\n","    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n","    for idx,frame in enumerate(frame_extract(path)):\n","      #if(idx % 3 == 0):\n","      if(idx <= 150):\n","        frames.append(frame)\n","        if(len(frames) == 4):\n","          faces = face_recognition.batch_face_locations(frames)\n","          for i,face in enumerate(faces):\n","            if(len(face) != 0):\n","              top,right,bottom,left = face[0]\n","            try:\n","              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n","            except:\n","              pass\n","          frames = []\n","    try:\n","      del top,right,bottom,left\n","    except:\n","      pass\n","    out.release()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n","Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566164 sha256=af4daaa23a84ddfd7fed11febaa2979dccbf739e63b0e8a322c65c5f5621af79\n","  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-8-606ab485ec1a>:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm\n"]}]},{"cell_type":"code","metadata":{"id":"sF5qiWGLvei-","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e72e59fd4e3b4734a1839204a9d74cf8","73ff9a5f69fd4e53a5072cfefa6d7531","35a650e5d4bb40df8bb9d0bf0799132b","f8a24ac30dcc4303bfd2f08e2825fca2","e559c28d63934ede822df8aff7634a9f","7f5967a9386347ccb185ee2116add86b","15010c60cf2d446d841189c3f94ba0b2","424b74d22ff8440eb70fdec197ffc38e","fe272ecc743a4cd8b85beb28519ea242","34cedcb7b9704974b09895d35d934092","507715d919bb40df9e93711565e07163"]},"outputId":"87515d27-c049-45ae-97da-1137ed57ab25"},"source":["create_face_videos(video_files,'/content/drive/My Drive/Face_only_data/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No of videos already present  0\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/63 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72e59fd4e3b4734a1839204a9d74cf8"}},"metadata":{}}]}]}